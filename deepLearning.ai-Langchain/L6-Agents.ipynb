{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "534561a9-8160-4502-a5bd-2b313918e9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.agents import load_tools, AgentType\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain_experimental.utilities.python import PythonREPL\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain_experimental.agents.agent_toolkits.python.base import create_python_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5c5b46d-cf1a-4873-aab3-48eb1251e307",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(temperature=0, model = \"qwen2.5:latest\") #pulled from ollama, local llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4e6043a-448f-4998-b043-7cd8c1fc2417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "996d0c55-9b43-40b4-91a2-3d8d9f6246ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"llm-math\", \"wikipedia\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7192442-4d06-424b-849a-7308c78f5418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Calculator', 'wikipedia']\n"
     ]
    }
   ],
   "source": [
    "print([tool.name for tool in tools])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d22d14e4-b030-4878-b023-44cd69078860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_99254/1066806611.py:1: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a4c4887-7ca7-4606-b5ab-dd8c65353e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_99254/1453878245.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  agent(\"What is the 25% of 300?\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mQuestion: What is the 25% of 300?\n",
      "Thought: I need to calculate 25% of 300, which can be done by multiplying 300 by 0.25.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"300 * 0.25\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 75.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The 25% of 300 is 75.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the 25% of 300?', 'output': 'The 25% of 300 is 75.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"What is the 25% of 300?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60432ad1-a606-4812-84b5-86592a55ca08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find out which book Tom M. Mitchell wrote. I should use the wikipedia tool for this.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"Tom M. Mitchell books\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPage: Tom M. Mitchell\n",
      "Summary: Tom Michael Mitchell (born August 9, 1951) is an American computer scientist and the Founders University Professor at Carnegie Mellon University (CMU). He is a founder and former chair of the Machine Learning Department at CMU. Mitchell is known for his contributions to the advancement of machine learning, artificial intelligence, and cognitive neuroscience and is the author of the textbook Machine Learning. He is a member of the United States National Academy of Engineering since 2010. He is also a Fellow of the American Academy of Arts and Sciences, the American Association for the Advancement of Science and a Fellow and past president of the Association for the Advancement of Artificial Intelligence. In October 2018, Mitchell was appointed as the Interim Dean of the School of Computer Science at Carnegie Mellon.\n",
      "\n",
      "Page: Hejira (album)\n",
      "Summary: Hejira is the eighth studio album by Canadian singer-songwriter Joni Mitchell, released in 1976 on Asylum Records. Its material was written during a period of frequent travel in late 1975 and early 1976, and reflects Mitchell's experiences on the road during that time. It is characterized by lyrically dense, sprawling songs and musical backing by several jazz-oriented instrumentalists, most prominently fretless bass player Jaco Pastorius, guitarist Larry Carlton, and drummer John Guerin.\n",
      "The album did not sell as well as its predecessors, peaking at No. 22 in Mitchell's native Canada. It reached No. 13 on the Billboard 200 pop album chart in the United States, where it was certified gold by the RIAA, and No. 11 in the UK, where it attained a silver certification. Critically, the album was generally well received, and in the years since its release, Hejira has been considered one of the high marks of her career. The lead track \"Coyote\" was released as a single.\n",
      "\n",
      "\n",
      "\n",
      "Page: Joni Mitchell\n",
      "Summary: Roberta Joan Mitchell  (nÃ©e Anderson; born November 7, 1943) is a Canadian and American singer-songwriter, multi-instrumentalist, and painter. As one of the most influential singer-songwriters to emerge from the 1960s folk music circuit, Mitchell became known for her personal lyrics and unconventional compositions, which grew to incorporate elements of pop, jazz, rock, and other genres. Among her accolades are eleven Grammy Awards, and induction into the Rock and Roll Hall of Fame in 1997. Rolling Stone, in 2002, named her \"one of the greatest songwriters ever\", and AllMusic, in a 2011 biography, stated \"Joni Mitchell may stand as the most important and influential female recording artist of the late 20th century.\"\n",
      "Mitchell began singing in small nightclubs in Saskatoon and throughout western Canada, before moving on to the nightclubs of Toronto. She moved to the United States and began touring in 1965. Some of her original songs (\"Urge for Going\", \"Chelsea Morning\", \"Both Sides, Now\", \"The Circle Game\") were recorded by other singers, allowing her to sign with Reprise Records and record her debut album, Song to a Seagull, in 1968. Settling in Southern California, Mitchell helped define an era and a generation with popular songs such as \"Big Yellow Taxi\" and \"Woodstock\" (both 1970). Her 1971 album Blue is often cited as one of the greatest albums of all time; it was rated the 30th best album ever made in Rolling Stone's 2003 list of the \"500 Greatest Albums of All Time\", rising to number 3 in the 2020 edition. In 2000, The New York Times chose Blue as one of the 25 albums that represented \"turning points and pinnacles in 20th-century popular music\". NPR ranked Blue number 1 on a 2017 list of the \"Greatest Albums Made By Women\".\n",
      "Mitchell began exploring more jazz-influenced ideas on 1974's Court and Spark, which featured the radio hits \"Help Me\" and \"Free Man in Paris\" and became her best-selling album. Mitchell's vocal range began to shift from mezzo-soprano to that of a wide-ranging contralto around 1975. Her distinctive piano and open-tuned guitar compositions also \u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mFrom the information provided by Wikipedia, it is clear that Tom M. Mitchell wrote a textbook titled \"Machine Learning\". However, there was no mention of any book written by Joni Mitchell in the summaries.\n",
      "Thought: I now know the final answer to the question about which book Tom M. Mitchell wrote.\n",
      "\n",
      "Final Answer: Tom M. Mitchell wrote the textbook \"Machine Learning\".\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"Tom M. Mitchell is an American computer scientist\n",
    "            and the Founders University Professor at Carnegie Mellon University (CMU)\n",
    "            what book did he write tell me?\n",
    "            \"\"\"\n",
    "result = agent(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13e8afe6-117d-4d41-afa2-87a6b7e24a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_python_agent(\n",
    "    llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa94b3d0-35af-4298-9f48-19b2118ac2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_list = [[\"Harrison\", \"Chase\"], \n",
    "                 [\"Lang\", \"Chain\"],\n",
    "                 [\"Dolly\", \"Too\"],\n",
    "                 [\"Elle\", \"Elem\"], \n",
    "                 [\"Geoff\",\"Fusion\"], \n",
    "                 [\"Trance\",\"Former\"],\n",
    "                 [\"Jen\",\"Ayai\"]\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c1f7520-3c3c-4ee4-a709-b8832149489b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mTo sort the list of customers by last name and then first name, I can use Python's `sorted` function with a custom key that extracts the last and first names.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: customers = [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\n",
      "sorted_customers = sorted(customers, key=lambda x: (x[1], x[0]))\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: Python_REPL\n",
      "Action Input: print(sorted_customers)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: The sorted list of customers by last name and then first name is [['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']].\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"Sort these customers by last name and then first name and print the output: [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\",\n",
       " 'output': \"The sorted list of customers by last name and then first name is [['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']].\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(f\"\"\"Sort these customers by \\\n",
    "last name and then first name \\\n",
    "and print the output: {customer_list}\"\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c8b57ec-1f9d-4336-8f0d-839a51dd901b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_99254/3881924213.py:3: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  agent.run(f\"\"\"Sort these customers by \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Sort these customers by last name and then first name and print the output: [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Sort these customers by last name and then first name and print the output: [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\",\n",
      "  \"agent_scratchpad\": \"\",\n",
      "  \"stop\": [\n",
      "    \"\\nObservation:\",\n",
      "    \"\\n\\tObservation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an agent designed to write and execute python code to answer questions.\\nYou have access to a python REPL, which you can use to execute python code.\\nIf you get an error, debug your code and try again.\\nOnly use the output of your code to answer the question. \\nYou might know the answer without running any code, but you should still run the code to get the answer.\\nIf it does not seem like you can write code to answer the question, just return \\\"I don't know\\\" as the answer.\\n\\n\\nPython_REPL - A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [Python_REPL]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: Sort these customers by last name and then first name and print the output: [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:ChatOllama] [23.54s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"qwen2.5:latest\",\n",
      "          \"created_at\": \"2025-06-04T11:05:08.881256382Z\",\n",
      "          \"done\": true,\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"total_duration\": 23535518540,\n",
      "          \"load_duration\": 13736097,\n",
      "          \"prompt_eval_count\": 350,\n",
      "          \"prompt_eval_duration\": 299819114,\n",
      "          \"eval_count\": 131,\n",
      "          \"eval_duration\": 23218507405,\n",
      "          \"model_name\": \"qwen2.5:latest\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"To sort the list of customers by last name and then first name, I can use Python's `sorted` function with a custom key that extracts the last and first names. Let's do this.\\nAction: Python_REPL\\nAction Input: customers = [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\\nsorted_customers = sorted(customers, key=lambda x: (x[1], x[0]))\\nprint(sorted_customers)\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"qwen2.5:latest\",\n",
      "              \"created_at\": \"2025-06-04T11:05:08.881256382Z\",\n",
      "              \"done\": true,\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"total_duration\": 23535518540,\n",
      "              \"load_duration\": 13736097,\n",
      "              \"prompt_eval_count\": 350,\n",
      "              \"prompt_eval_duration\": 299819114,\n",
      "              \"eval_count\": 131,\n",
      "              \"eval_duration\": 23218507405,\n",
      "              \"model_name\": \"qwen2.5:latest\"\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--58abd5cc-00da-4657-948c-f8f2a1475a75-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 350,\n",
      "              \"output_tokens\": 131,\n",
      "              \"total_tokens\": 481\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        },\n",
      "        \"text\": \"To sort the list of customers by last name and then first name, I can use Python's `sorted` function with a custom key that extracts the last and first names. Let's do this.\\nAction: Python_REPL\\nAction Input: customers = [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\\nsorted_customers = sorted(customers, key=lambda x: (x[1], x[0]))\\nprint(sorted_customers)\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] [23.54s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"To sort the list of customers by last name and then first name, I can use Python's `sorted` function with a custom key that extracts the last and first names. Let's do this.\\nAction: Python_REPL\\nAction Input: customers = [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\\nsorted_customers = sorted(customers, key=lambda x: (x[1], x[0]))\\nprint(sorted_customers)\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:Python_REPL] Entering Tool run with input:\n",
      "\u001b[0m\"customers = [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\n",
      "sorted_customers = sorted(customers, key=lambda x: (x[1], x[0]))\n",
      "print(sorted_customers)\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:Python_REPL] [1ms] Exiting Tool run with output:\n",
      "\u001b[0m\"[['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Sort these customers by last name and then first name and print the output: [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\",\n",
      "  \"agent_scratchpad\": \"To sort the list of customers by last name and then first name, I can use Python's `sorted` function with a custom key that extracts the last and first names. Let's do this.\\nAction: Python_REPL\\nAction Input: customers = [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\\nsorted_customers = sorted(customers, key=lambda x: (x[1], x[0]))\\nprint(sorted_customers)\\nObservation: [['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]\\n\\nThought:\",\n",
      "  \"stop\": [\n",
      "    \"\\nObservation:\",\n",
      "    \"\\n\\tObservation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an agent designed to write and execute python code to answer questions.\\nYou have access to a python REPL, which you can use to execute python code.\\nIf you get an error, debug your code and try again.\\nOnly use the output of your code to answer the question. \\nYou might know the answer without running any code, but you should still run the code to get the answer.\\nIf it does not seem like you can write code to answer the question, just return \\\"I don't know\\\" as the answer.\\n\\n\\nPython_REPL - A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [Python_REPL]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: Sort these customers by last name and then first name and print the output: [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\\nThought:To sort the list of customers by last name and then first name, I can use Python's `sorted` function with a custom key that extracts the last and first names. Let's do this.\\nAction: Python_REPL\\nAction Input: customers = [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\\nsorted_customers = sorted(customers, key=lambda x: (x[1], x[0]))\\nprint(sorted_customers)\\nObservation: [['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]\\n\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain > llm:ChatOllama] [11.38s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"qwen2.5:latest\",\n",
      "          \"created_at\": \"2025-06-04T11:05:20.260140104Z\",\n",
      "          \"done\": true,\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"total_duration\": 11372769089,\n",
      "          \"load_duration\": 15570332,\n",
      "          \"prompt_eval_count\": 535,\n",
      "          \"prompt_eval_duration\": 912799239,\n",
      "          \"eval_count\": 62,\n",
      "          \"eval_duration\": 10439158504,\n",
      "          \"model_name\": \"qwen2.5:latest\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"I now know the final answer\\nFinal Answer: The customers sorted by last name and then first name are as follows:\\n\\n1. Jen Ayai\\n2. Lang Chain\\n3. Harrison Chase\\n4. Elle Elem\\n5. Trance Former\\n6. Geoff Fusion\\n7. Dolly Too\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"qwen2.5:latest\",\n",
      "              \"created_at\": \"2025-06-04T11:05:20.260140104Z\",\n",
      "              \"done\": true,\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"total_duration\": 11372769089,\n",
      "              \"load_duration\": 15570332,\n",
      "              \"prompt_eval_count\": 535,\n",
      "              \"prompt_eval_duration\": 912799239,\n",
      "              \"eval_count\": 62,\n",
      "              \"eval_duration\": 10439158504,\n",
      "              \"model_name\": \"qwen2.5:latest\"\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--0a7ed198-6947-4a81-b5ae-e2dad192d03e-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 535,\n",
      "              \"output_tokens\": 62,\n",
      "              \"total_tokens\": 597\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        },\n",
      "        \"text\": \"I now know the final answer\\nFinal Answer: The customers sorted by last name and then first name are as follows:\\n\\n1. Jen Ayai\\n2. Lang Chain\\n3. Harrison Chase\\n4. Elle Elem\\n5. Trance Former\\n6. Geoff Fusion\\n7. Dolly Too\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:LLMChain] [11.38s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"I now know the final answer\\nFinal Answer: The customers sorted by last name and then first name are as follows:\\n\\n1. Jen Ayai\\n2. Lang Chain\\n3. Harrison Chase\\n4. Elle Elem\\n5. Trance Former\\n6. Geoff Fusion\\n7. Dolly Too\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor] [34.92s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The customers sorted by last name and then first name are as follows:\\n\\n1. Jen Ayai\\n2. Lang Chain\\n3. Harrison Chase\\n4. Elle Elem\\n5. Trance Former\\n6. Geoff Fusion\\n7. Dolly Too\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "langchain.debug=True\n",
    "agent.run(f\"\"\"Sort these customers by \\\n",
    "last name and then first name \\\n",
    "and print the output: {customer_list}\"\"\") \n",
    "langchain.debug=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cfbe4e-6a41-4481-a6c9-e532822417f8",
   "metadata": {},
   "source": [
    "# Define your own tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2e72d53e-7900-410e-84fb-34dfcafffc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "32579550-d147-46cc-bf64-5cde733208a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def time(text: str) -> str:\n",
    "    \"\"\"Returns todays date, use this for any\n",
    "    questions related to knowing todays date.\n",
    "    The input should always be an empty string,\n",
    "    and this function will always return todays\n",
    "    date - any date mathmatics should occur\n",
    "    outside this function.\n",
    "    \"\"\"\n",
    "    return str(date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "778c167f-8fc9-431e-abbd-11dbf4d9db20",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    tools + [time],\n",
    "    llm,\n",
    "    agent = AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b103af63-6b4b-45a6-8830-75c7ff484ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mQuestion: whats the date today?\n",
      "Thought: I need to get today's date.\n",
      "Action:\n",
      "```\n",
      "{\"action\": \"time\", \"action_input\": \"\"}\n",
      "``` \n",
      "\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m2025-06-04\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: Today's date is June 4, 2025.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    result = agent(\"whats the date today?\")\n",
    "except:\n",
    "    print(\"exception on external access\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4409d7da-c4e4-4d57-8871-07daaa82fefd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

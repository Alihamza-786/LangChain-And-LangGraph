{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86e0cefe-3931-43a5-9ea4-7293a54988e9",
   "metadata": {},
   "source": [
    "# Streaming With Langchain\n",
    "LangChain is one of the most popular open source libraries for AI Engineers. It's goal is to abstract away the complexity in building AI software, provide easy-to-use building blocks, and make it easier when switching between AI service providers.\n",
    "\n",
    "In this example, we will introduce LangChain's async streaming, allowing us to receive and view the tokens as they are generated by Ollama LLM. The use of streaming is typical in conversational interfaces and can provide a more natural experience for users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a9aec4-9a62-4729-b0a2-2f27adc6ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(\n",
    "    model = \"llama3.2\",\n",
    "    temperatur=0.0,\n",
    "    streaming=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df273495-5ae6-41f0-9f65-c21a8241121e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! It's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-05-15T05:36:27.5757625Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1797605200, 'load_duration': 342883100, 'prompt_eval_count': 27, 'prompt_eval_duration': 611695400, 'eval_count': 25, 'eval_duration': 839109300, 'model_name': 'llama3.2'}, id='run--edd8fc65-1796-4c58-be8f-cdfce30977a1-0', usage_metadata={'input_tokens': 27, 'output_tokens': 25, 'total_tokens': 52})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_out = llm.invoke(\"Hello there\")\n",
    "llm_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cddb12-f00b-48db-842a-690f6ae5b52b",
   "metadata": {},
   "source": [
    "# Streaming with astream\n",
    "We will start by creating a aysnc stream from our LLM. We do this within an async for loop, allowing us to iterate through the chunks of data and use them as soon as the async astream method returns the tokens to us. By adding a pipe character | we can see the individual tokens that are generated. We set flush equal to True as this forces immediate output to the console, resulting in smoother streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28d0780f-c0d3-4898-a9b2-fc3ddc302f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N|LP| stands| for| Natural| Language| Processing|,| which| is| a| sub|field| of| artificial| intelligence| (|AI|)| that| deals| with| the| interaction| between| computers| and| humans| in| natural| language|.| It| involves| the| use| of| algorithms|,| statistical| models|,| and| machine| learning| techniques| to| process|,| understand|,| and| generate| human| language|.\n",
      "\n",
      "|The| primary| goals| of| N|LP| are|:\n",
      "\n",
      "|1|.| **|Text| Analysis|**:| To| extract| meaningful| information| from| text| data|,| such| as| sentiment| analysis|,| named| entity| recognition|,| and| topic| modeling|.\n",
      "|2|.| **|Language| Understanding|**:| To| comprehend| the| meaning| of| natural| language| inputs|,| including| syntax|,| semantics|,| and| prag|m|atics|.\n",
      "|3|.| **|Language| Generation|**:| To| generate| human|-like| text| or| speech| that| is| coherent|,| gramm|atically| correct|,| and| context|ually| relevant|.\n",
      "\n",
      "|Some| common| N|LP| applications| include|:\n",
      "\n",
      "|1|.| Sent|iment| analysis|:| Analy|zing| customer| reviews| to| determine| sentiment| towards| a| product| or| service|.\n",
      "|2|.| Machine| translation|:| Trans|l|ating| text| from| one| language| to| another|.\n",
      "|3|.| Question| answering|:| Respond|ing| to| questions| based| on| the| content| of| a| document| or| database|.\n",
      "|4|.| Chat|bots|:| Building| convers|ational| interfaces| that| can| understand| and| respond| to| user| queries|.\n",
      "|5|.| Speech| recognition|:| Con|verting| spoken| language| into| text|.\n",
      "\n",
      "|N|LP| has| many| applications| in| various| industries|,| including|:\n",
      "\n",
      "|1|.| **|Virtual| assistants|**:| Siri|,| Alexa|,| Google| Assistant|\n",
      "|2|.| **|Language| learning| platforms|**:| Du|ol|ingo|\n",
      "|3|.| **|Sent|iment| analysis| tools|**:| Brand|watch|,| H|oot|suite|\n",
      "|4|.| **|Customer| service| chat|bots|**:| Many| companies| use| N|LP|-powered| chat|bots| to| handle| customer| inquiries|.\n",
      "|5|.| **|Speech| recognition| systems|**:| Many| smartphones| and| voice| assistants| rely| on| N|LP| for| speech| recognition|.\n",
      "\n",
      "|Overall|,| N|LP| has| revolution|ized| the| way| we| interact| with| computers| and| analyze| human| language|,| enabling| applications| that| were| previously| unimagin|able|.||"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "async for token in llm.astream(\"What is NLP?\"):\n",
    "    tokens.append(token)\n",
    "    print(token.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaea3225-d606-47c0-ab34-b1b63def0632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='N', additional_kwargs={}, response_metadata={}, id='run--9f22dba6-1d03-4100-a9f5-1ba08e918ef3')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f035f8f-d510-4e97-a697-4ee853cfd135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='LP', additional_kwargs={}, response_metadata={}, id='run--9f22dba6-1d03-4100-a9f5-1ba08e918ef3')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[1]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "31787600-7bf1-4edb-8857-7b73abe4fd14",
   "metadata": {},
   "source": [
    "We can also merge multiple AIMessageChunk objects together with the + operator, creating a larger set of tokens / chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c468dc24-cb80-4eaa-af21-49815f98ecea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='NLP stands for Natural', additional_kwargs={}, response_metadata={}, id='run--9f22dba6-1d03-4100-a9f5-1ba08e918ef3')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[0] + tokens[1] + tokens[2] + tokens[3] + tokens[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e86ddf-798b-4b34-bb4a-9fa071be7c57",
   "metadata": {},
   "source": [
    "A word of caution, there is nothing preventing you from merging tokens in the incorrect order, so be cautious to not output any token omelettes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ff53e04-00f9-433f-8d35-6a8a0df51934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=' Natural for standsLPN', additional_kwargs={}, response_metadata={}, id='run--9f22dba6-1d03-4100-a9f5-1ba08e918ef3')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[4] + tokens[3] + tokens[2] + tokens[1] + tokens[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea35796-02fb-42dd-a047-4b5e5ae6e1bd",
   "metadata": {},
   "source": [
    "# Streaming with Agents\n",
    "Streaming with agents, particularly the custom agent executor, is a little more complex. Let's begin by constructor a simple agent executor matching what we built in the Agent Executor chapter.\n",
    "\n",
    "To construct the agent executor we need:\n",
    "\n",
    "- Tools\n",
    "- ChatPromptTemplate\n",
    "- Our LLM (already defined with llm)\n",
    "- An agent\n",
    "- Finally, the agent executor\n",
    "\n",
    "Let's start defining each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160eb32c-fca7-4179-8c38-152a2f20615c",
   "metadata": {},
   "source": [
    "# Tools\n",
    "Now we will define a few tools to be used by an async agent executor. Our goal for tool-use in regards to streaming are:\n",
    "\n",
    "- The tool-use steps will be streamed in one big chunk, ie we do not return the tool use information token-by-token but instead it streams message-by-message.\n",
    "\n",
    "- The final LLM output will be streamed token-by-token as we saw above.\n",
    "\n",
    "For these we need to define a few math tools and our final answer tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ca7c99d-ea0a-45eb-8edd-ddee593ae2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(x: float, y: float) -> float:\n",
    "    \"\"\"Add 'x' and 'y'.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "@tool\n",
    "def multiply(x: float, y: float) -> float:\n",
    "    \"\"\"Multiply 'x' and 'y'.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "@tool\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise 'x' to the power of 'y'.\"\"\"\n",
    "    return x ** y\n",
    "\n",
    "@tool\n",
    "def subtract(x: float, y: float) -> float:\n",
    "    \"\"\"Subtract 'x' from 'y'.\"\"\"\n",
    "    return y - x\n",
    "\n",
    "@tool\n",
    "def final_answer(answer: str, tools_used: list[str]) -> str:\n",
    "    \"\"\"Use this tool to provide a final answer to the user.\n",
    "    The answer should be in natural language as this will be provided\n",
    "    to the user directly. The tools_used must include a list of tool\n",
    "    names that were used within the `scratchpad`. You MUST use this tool\n",
    "    to conclude the interaction.\n",
    "    \"\"\"\n",
    "    return {\"answer\": answer, \"tools_used\": tools_used}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3fcb3bb-6e86-4c6a-b3c6-2f49850daaad",
   "metadata": {},
   "source": [
    "We'll need all of our tools in a list when defining our agent and agent_executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6e5a869-4646-41ae-ad8d-e65dd1ec9697",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [add, multiply, exponentiate, subtract, final_answer]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3cf351-74ce-433b-8c88-310f9342b1d8",
   "metadata": {},
   "source": [
    "# ChatPromptTemplate\n",
    "We will create our ChatPromptTemplate, using a system message, chat history, user input, and a scratchpad for intermediate steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "518fb322-abde-406a-990b-f3bde7698da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", (\n",
    "        \"You're a helpful assistant. When answering a user's question \"\n",
    "        \"you should first use one of the tools provided. After using a \"\n",
    "        \"tool the tool output will be provided back to you. You MUST \"\n",
    "        \"then use the final_answer tool to provide a final answer to the user. \"\n",
    "        \"DO NOT use the same tool more than once.\"\n",
    "    )),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903552ef-80a9-4718-8734-526443c1c5b4",
   "metadata": {},
   "source": [
    "# Agent\n",
    "As before, we will define our agent with LCEL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d582fc1-f36d-4b5f-898a-d9415f61d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.base import RunnableSerializable\n",
    "\n",
    "tools = [add, subtract, multiply, exponentiate, final_answer]\n",
    "\n",
    "# define the agent runnable\n",
    "agent: RunnableSerializable = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice=\"any\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad63e69d-b870-4a74-adb4-ff88e522eed2",
   "metadata": {},
   "source": [
    "# Agent Executor\n",
    "Finally, we will create the agent executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b806d88-a935-4c65-9e27-b0905cc841d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "\n",
    "\n",
    "# create tool name to function mapping\n",
    "name2tool = {tool.name: tool.func for tool in tools}\n",
    "\n",
    "class CustomAgentExecutor:\n",
    "    chat_history: list[BaseMessage]\n",
    "\n",
    "    def __init__(self, max_iterations: int = 3):\n",
    "        self.chat_history = []\n",
    "        self.max_iterations = max_iterations\n",
    "        self.agent: RunnableSerializable = (\n",
    "            {\n",
    "                \"input\": lambda x: x[\"input\"],\n",
    "                \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "                \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
    "            }\n",
    "            | prompt\n",
    "            | llm.bind_tools(tools, tool_choice=\"any\")  # we're forcing tool use again\n",
    "        )\n",
    "\n",
    "    def invoke(self, input: str) -> dict:\n",
    "        # invoke the agent but we do this iteratively in a loop until\n",
    "        # reaching a final answer\n",
    "        count = 0\n",
    "        agent_scratchpad = []\n",
    "        while count < self.max_iterations:\n",
    "            # invoke a step for the agent to generate a tool call\n",
    "            out = self.agent.invoke({\n",
    "                \"input\": input,\n",
    "                \"chat_history\": self.chat_history,\n",
    "                \"agent_scratchpad\": agent_scratchpad\n",
    "            })\n",
    "            # if the tool call is the final answer tool, we stop\n",
    "            if out.tool_calls[0][\"name\"] == \"final_answer\":\n",
    "                break\n",
    "            agent_scratchpad.append(out)  # add tool call to scratchpad\n",
    "            # otherwise we execute the tool and add it's output to the agent scratchpad\n",
    "            tool_out = name2tool[out.tool_calls[0][\"name\"]](**out.tool_calls[0][\"args\"])\n",
    "            # add the tool output to the agent scratchpad\n",
    "            action_str = f\"The {out.tool_calls[0]['name']} tool returned {tool_out}\"\n",
    "            agent_scratchpad.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": action_str,\n",
    "                \"tool_call_id\": out.tool_calls[0][\"id\"]\n",
    "            })\n",
    "            # add a print so we can see intermediate steps\n",
    "            print(f\"{count}: {action_str}\")\n",
    "            count += 1\n",
    "        # add the final output to the chat history\n",
    "        final_answer = out.tool_calls[0][\"args\"]\n",
    "        # this is a dictionary, so we convert it to a string for compatibility with\n",
    "        # the chat history\n",
    "        final_answer_str = json.dumps(final_answer)\n",
    "        self.chat_history.append({\"input\": input, \"output\": final_answer_str})\n",
    "        self.chat_history.extend([\n",
    "            HumanMessage(content=input),\n",
    "            AIMessage(content=final_answer_str)\n",
    "        ])\n",
    "        # return the final answer in dict form\n",
    "        return final_answer\n",
    "\n",
    "agent_executor = CustomAgentExecutor()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b58a58af-2b86-4f93-941a-45b1c8a0fda4",
   "metadata": {},
   "source": [
    "Our agent_executor is now ready to use, let's quickly test it before adding streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfdd963-7e41-43af-a65c-f6935dcd2e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke(input=\"What is 10 + 10\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a85481d5-8bf1-43ad-9e09-9d890537a80a",
   "metadata": {},
   "source": [
    "# LangChain Agent Executor\n",
    "In this chapter, we will continue from the introduction to agents and dive deeper into agents. Learning how to build our custom agent execution loop for v0.3 of LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf15fd05-3f30-44a4-bb5c-5879843b4cfb",
   "metadata": {},
   "source": [
    "![Agent Executor](images/agentExecutor.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3822e895-b5cf-4095-8e97-bb0f3a948c2d",
   "metadata": {},
   "source": [
    "We have user input that goes into LLm then..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3123f0-1f92-49c9-b5d7-eb9bd5613024",
   "metadata": {},
   "source": [
    "![Agent Executor](images/agentExecutor2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c7a777-7711-463d-9676-7eb1bae991a7",
   "metadata": {},
   "source": [
    "# Tools\n",
    "As with the previous chapter, we will define a few tools to use within our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd8fd76f-2e60-4215-8905-25187684f854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(x: float, y: float) -> float:\n",
    "    \"\"\"Add 'x' and 'y'.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "# Define the multiply tool\n",
    "@tool\n",
    "def multiply(x: float, y: float) -> float:\n",
    "    \"\"\"Multiply 'x' and 'y'.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "# Define the exponentiate tool\n",
    "@tool\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise 'x' to the power of 'y'.\"\"\"\n",
    "    return x ** y\n",
    "\n",
    "@tool\n",
    "def subtract(x: float, y: float) -> float:\n",
    "    \"\"\"Subtract 'x' from 'y'.\"\"\"\n",
    "    return y - x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1fb47845-8c56-43e6-a2db-a916cdb6f04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='add', description=\"Add 'x' and 'y'.\", args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x00000268F4403420>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7bc5001d-feae-45e3-85f1-57d50c8296e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add.name='add'\n",
      "add.description=\"Add 'x' and 'y'.\"\n"
     ]
    }
   ],
   "source": [
    "print(f\"{add.name=}\\n{add.description=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "24347bbe-674d-438e-b4cb-da5587d0750b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': \"Add 'x' and 'y'.\",\n",
       " 'properties': {'x': {'title': 'X', 'type': 'number'},\n",
       "  'y': {'title': 'Y', 'type': 'number'}},\n",
       " 'required': ['x', 'y'],\n",
       " 'title': 'add',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c8e56e9-d7ea-4bb2-992c-9c0b93d07272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': \"Raise 'x' to the power of 'y'.\",\n",
       " 'properties': {'x': {'title': 'X', 'type': 'number'},\n",
       "  'y': {'title': 'Y', 'type': 'number'}},\n",
       " 'required': ['x', 'y'],\n",
       " 'title': 'exponentiate',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponentiate.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "893fe73f-26cd-4e30-93f9-1f5fc501f459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "llm_output_string = \"{\\\"x\\\": 5, \\\"y\\\": 2}\"  # this is the output from the LLM\n",
    "llm_output_dict = json.loads(llm_output_string)  # load as dictionary\n",
    "llm_output_dict\n",
    "\n",
    "\n",
    "exponentiate.func(**llm_output_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86267df-552e-4680-9dd1-9f89e8a11084",
   "metadata": {},
   "source": [
    "# Creating an Agent\n",
    "We will use LangChain Epression Language (LCEL) to construct the agent. We will cover LCEL more in the next chapter, but for now - all we need to know is that our agent will be constructed using syntax and components like so:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6e04dd6a-844c-4725-98bf-857fe0e97039",
   "metadata": {},
   "source": [
    "agent = (\n",
    "    <input parameters, including chat history and user query>\n",
    "    | <prompt>\n",
    "    | <LLM with tools>\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "64cb1bd6-2e6f-48f9-a3a2-62c282f2c3de",
   "metadata": {},
   "source": [
    "We need this agent to remember previous interactions within the conversation. To do that, we will use the ChatPromptTemplate with a system message, a placeholder for our chat history, a placeholder for the user query, and finally a placeholder for the agent scratchpad.\n",
    "\n",
    "The agent scratchpad is where the agent writes its notes as it works through multiple internal thought and tool-use steps to produce a final output for the user. This scratchpad is a list of messages with alternating roles of ai (for the tool call) and tool (for the tool execution output). Both message types require a tool_call_id field which is used to link the respective AI and tool messages - this can be required when we many tool calls happening in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26b129d7-b1ac-47e0-988a-cff5e85e663f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", (\n",
    "        \"You're a helpful assistant. When answering a user's question \"\n",
    "        \"you should first use one of the tools provided. After using a \"\n",
    "        \"tool the tool output will be provided in the \"\n",
    "        \"'scratchpad' below. If you have an answer in the \"\n",
    "        \"scratchpad you should not use any more tools and \"\n",
    "        \"instead answer directly to the user.\"\n",
    "    )),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1d3ecf4f-97a7-46b2-9cc9-1eee5d7dc495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "model_name = \"llama3.1\"\n",
    "# smaller alternative: llama3.2:3b-instruct-fp16\n",
    "\n",
    "# initialize one LLM with temperature 0.0, this makes the LLM more deterministic\n",
    "llm = ChatOllama(model=model_name, temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ff60284-2d31-42b8-b84c-7d4b57aee177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.base import RunnableSerializable\n",
    "\n",
    "tools = [add, subtract, multiply, exponentiate]\n",
    "\n",
    "# define the agent runnable\n",
    "agent: RunnableSerializable = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice=\"any\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb3ed8ae-34ce-47fe-b4ee-b154016efe85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-05-15T08:26:48.2101241Z', 'done': True, 'done_reason': 'stop', 'total_duration': 15110344300, 'load_duration': 4349157800, 'prompt_eval_count': 411, 'prompt_eval_duration': 1101354900, 'eval_count': 46, 'eval_duration': 9655095000, 'model_name': 'llama3.1'}, id='run--b792435b-e437-45b7-8079-fa3beff8828c-0', tool_calls=[{'name': 'add', 'args': {'x': 10, 'y': 10}, 'id': '889f7562-d97a-4821-a0a1-849ac2ccbd1d', 'type': 'tool_call'}, {'name': 'add', 'args': {'x': 10, 'y': 10}, 'id': 'fd4502a2-d617-4de7-bcfb-f10757329af8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 411, 'output_tokens': 46, 'total_tokens': 457})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = agent.invoke({\"input\": \"What is 10 + 10\", \"chat_history\": []})\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "00c82fdb-a8a4-4096-a042-5e01c13a993b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'x': 10, 'y': 10},\n",
       "  'id': '889f7562-d97a-4821-a0a1-849ac2ccbd1d',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'add',\n",
       "  'args': {'x': 10, 'y': 10},\n",
       "  'id': 'fd4502a2-d617-4de7-bcfb-f10757329af8',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "79fa389e-c5c3-45d2-a06a-8959ab3f5a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tool name to function mapping\n",
    "name2tool = {tool.name: tool.func for tool in tools}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "270e5c22-c689-4baf-898d-ac4ee934d26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_exec_content = name2tool[tool_call.tool_calls[0][\"name\"]](\n",
    "    **tool_call.tool_calls[0][\"args\"]\n",
    ")\n",
    "tool_exec_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "20ca9611-2201-4d66-bf16-4352b11c8f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The answer to the question is 20.', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-05-15T08:28:37.8233646Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2299329400, 'load_duration': 25794600, 'prompt_eval_count': 181, 'prompt_eval_duration': 632601000, 'eval_count': 10, 'eval_duration': 1637171200, 'model_name': 'llama3.1'}, id='run--42285fd8-e4cb-45c6-9e60-0d3a29639cf8-0', usage_metadata={'input_tokens': 181, 'output_tokens': 10, 'total_tokens': 191})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "tool_exec = ToolMessage(\n",
    "    content=f\"The {tool_call.tool_calls[0]['name']} tool returned {tool_exec_content}\",\n",
    "    tool_call_id=tool_call.tool_calls[0][\"id\"]\n",
    ")\n",
    "\n",
    "out = agent.invoke({\n",
    "    \"input\": \"What is 10 + 10\",\n",
    "    \"chat_history\": [],\n",
    "    \"agent_scratchpad\": [tool_call, tool_exec]\n",
    "})\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c138c04d-adcb-47c5-a465-22c525eab70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent: RunnableSerializable = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice=\"auto\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "64878661-b5d2-46aa-8447-62a7d5950e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-05-15T08:29:48.9015028Z', 'done': True, 'done_reason': 'stop', 'total_duration': 10658337400, 'load_duration': 18766800, 'prompt_eval_count': 411, 'prompt_eval_duration': 956053200, 'eval_count': 46, 'eval_duration': 9681283100, 'model_name': 'llama3.1'}, id='run--6479c606-0172-4d7f-a79d-42163ad3ccaf-0', tool_calls=[{'name': 'add', 'args': {'x': 10, 'y': 10}, 'id': '5736edfe-743a-4ed7-8a0f-69710db121c2', 'type': 'tool_call'}, {'name': 'add', 'args': {'x': 10, 'y': 10}, 'id': '102b6ad7-943b-4cb0-b477-de98b2264974', 'type': 'tool_call'}], usage_metadata={'input_tokens': 411, 'output_tokens': 46, 'total_tokens': 457})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = agent.invoke({\"input\": \"What is 10 + 10\", \"chat_history\": []})\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4463e066-79be-4b97-812d-7beee220eb40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The answer to the question is 20.', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-05-15T08:30:03.8385916Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2376580000, 'load_duration': 17710200, 'prompt_eval_count': 181, 'prompt_eval_duration': 685940200, 'eval_count': 10, 'eval_duration': 1671405000, 'model_name': 'llama3.1'}, id='run--d237fd5a-beea-48d9-9c54-21dd4e688360-0', usage_metadata={'input_tokens': 181, 'output_tokens': 10, 'total_tokens': 191})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_output = name2tool[tool_call.tool_calls[0][\"name\"]](\n",
    "    **tool_call.tool_calls[0][\"args\"]\n",
    ")\n",
    "\n",
    "tool_exec = ToolMessage(\n",
    "    content=f\"The {tool_call.tool_calls[0]['name']} tool returned {tool_output}\",\n",
    "    tool_call_id=tool_call.tool_calls[0][\"id\"]\n",
    ")\n",
    "\n",
    "out = agent.invoke({\n",
    "    \"input\": \"What is 10 + 10\",\n",
    "    \"chat_history\": [],\n",
    "    \"agent_scratchpad\": [tool_call, tool_exec]\n",
    "})\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6b6d2d1e-3905-46d6-8023-e65a50adb02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def final_answer(answer: str, tools_used: list[str]) -> str:\n",
    "    \"\"\"Use this tool to provide a final answer to the user.\n",
    "    The answer should be in natural language as this will be provided\n",
    "    to the user directly. The tools_used must include a list of tool\n",
    "    names that were used within the `scratchpad`.\n",
    "    \"\"\"\n",
    "    return {\"answer\": answer, \"tools_used\": tools_used}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "671b2e01-da59-41fc-8e88-a0bd2541fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [final_answer, add, subtract, multiply, exponentiate]\n",
    "\n",
    "# we need to update our name2tool mapping too\n",
    "name2tool = {tool.name: tool.func for tool in tools}\n",
    "\n",
    "agent: RunnableSerializable = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice=\"any\")  # we're forcing tool use again\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a6774fa2-0a70-42a6-9736-a240dd8ff5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'x': 10, 'y': 10},\n",
       "  'id': 'edfcf7cb-93a3-4eb3-82c4-2f4bff26c4c7',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'add',\n",
       "  'args': {'x': 10, 'y': 10},\n",
       "  'id': '3188d9b9-14ce-4811-8e1d-2dede6519616',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = agent.invoke({\"input\": \"What is 10 + 10\", \"chat_history\": []})\n",
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d744d970-c3ee-4fcb-a39c-9bfcb64105f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 10, 'y': 10}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = agent.invoke({\"input\": \"What is 10 + 10\", \"chat_history\": []})\n",
    "tool_call.tool_calls[0][\"args\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "547cba62-b6d1-4c45-890d-8517a461c477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The answer to the question is 20.', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-05-15T08:31:37.7203508Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2488898800, 'load_duration': 17413600, 'prompt_eval_count': 181, 'prompt_eval_duration': 675778100, 'eval_count': 10, 'eval_duration': 1793923600, 'model_name': 'llama3.1'}, id='run--0398bd04-4e7b-44fa-abad-1f46f8a3abd9-0', usage_metadata={'input_tokens': 181, 'output_tokens': 10, 'total_tokens': 191})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_out = name2tool[tool_call.tool_calls[0][\"name\"]](\n",
    "    **tool_call.tool_calls[0][\"args\"]\n",
    ")\n",
    "\n",
    "tool_exec = ToolMessage(\n",
    "    content=f\"The {tool_call.tool_calls[0]['name']} tool returned {tool_out}\",\n",
    "    tool_call_id=tool_call.tool_calls[0][\"id\"]\n",
    ")\n",
    "\n",
    "out = agent.invoke({\n",
    "    \"input\": \"What is 10 + 10\",\n",
    "    \"chat_history\": [],\n",
    "    \"agent_scratchpad\": [tool_call, tool_exec]\n",
    "})\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0191c320-188e-4270-9614-ebf04adcebeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e2a572-2d0e-44ab-9fb6-c599bce2663c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
